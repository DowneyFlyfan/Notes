---
id: 学习率调度
aliases: []
tags: []
---

# 学习率调度
*   Cosine Annealing LR

1.  公式\\[\eta = \eta_{min} + \frac{1}{2} (\eta_{max} - \eta_{min}) \lbrack 1 + \cos ( \frac{t}{T_{max}} \pi) \rbrack](\eta_{max}: 开始的学习率$  
    (\eta_{min}: 最后的学习率$  
    (t:当前步$  
    (T_{max}: 最大步$  
      
    
2.  实现代码  
    scheduler = lr_scheduler.CosineAnnealingLR(optimizer, T_max=100)  
    
*   Exponential LR  
    

1.  公式: (lr = lr \times \gamma^t$  
    (t$: 步数  
    (\gamma$: 学习率  
      
    
2.  代码  
    lr_scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer=optimizer, gamma=args.gamma)
